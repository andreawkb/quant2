{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Outliers & Primary Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First detect outliers and decide what to do with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"psych\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(psych)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read.csv(\"Task3_data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the summary of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "describe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution of data; not likely to be normally distributed given Likert scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist(df$PER1)\n",
    "hist(df$PER2)\n",
    "hist(df$PER3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use boxplots to detect univariate outliers as data not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxplot(df$PER1)\n",
    "boxplot(df$PER2)\n",
    "boxplot(df$PER3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxplot(df$RUM1)\n",
    "boxplot(df$RUM2)\n",
    "boxplot(df$RUM3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxplot(df$EX1)\n",
    "boxplot(df$EX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxplot(df$EX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxplot(df$EX4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate outliers found in PER2, RUM1 and EX1. Quite a lot found for RUM1. Exclusion will reduce sample size by quite a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use mahalanobis distance to detect multivariate outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = mahalanobis(df, center = colMeans(df, na.rm = T), cov = cov(df, use = \"complete.obs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha <- .001\n",
    "cutoff <- (qchisq(p = 1 - alpha, df = ncol(df)))\n",
    "outlierID.mah=df$X[md > cutoff]\n",
    "\n",
    "# remove NAs\n",
    "outlierID.mah=outlierID.mah[!is.na(outlierID.mah)]\n",
    "outlierID.mah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winsorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's winsorize rather than exclude outliers as there are quite a few of them, especially for RUM1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsorize <- function(x, probs = NULL, cutpoints = NULL , replace = c(cutpoints[1], cutpoints[2]), verbose = TRUE){\n",
    "  dummy = is.integer(x)\n",
    "  if (!is.null(probs)){\n",
    "    stopifnot(is.null(cutpoints))\n",
    "    stopifnot(length(probs)==2)\n",
    "    cutpoints <- quantile(x, probs, type = 1, na.rm = TRUE)\n",
    "  } else if (is.null(cutpoints)){\n",
    "    l <- quantile(x, c(0.25, 0.50, 0.75), type = 1, na.rm = TRUE) \n",
    "    cutpoints <- c(l[2]-3*(l[3]-l[1]), l[2]+3*(l[3]-l[1]))  ### Default was 5*IQR but has been changed to 3*IQR\n",
    "  } else{\n",
    "    stopifnot(length(cutpoints)==2)\n",
    "  }\n",
    "  if (is.integer(x)) cutpoints <- round(cutpoints)\n",
    "  bottom <- x < cutpoints[1]\n",
    "  top <- x > cutpoints[2]\n",
    "  if (verbose){\n",
    "    length <- length(x)\n",
    "    message(paste(100*sum(bottom, na.rm = TRUE)/length,\"% observations replaced at the bottom\"))\n",
    "    message(paste(100*sum(top, na.rm = TRUE)/length,\"% observations replaced at the top\"))\n",
    "  }\n",
    "  x[bottom] <- replace[1]\n",
    "  x[top] <- replace[2]\n",
    "  if (dummy){\n",
    "    x <- as.integer(x)\n",
    "  }\n",
    "  x\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = apply(df,2,winsorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use lavaan to run CFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "install.packages(\"lavaan\", dependencies = TRUE)\n",
    "library(lavaan)\n",
    "example(cfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = 'Perfectionism =~ PER1 + PER2 + PER3\n",
    " Rumination =~ RUM1 + RUM2 + RUM3\n",
    " Exhaustion =~ EX1 + EX2 + EX3 + EX4'\n",
    "\n",
    "fit = cfa(model, data=df1)\n",
    "\n",
    "summary(fit, fit.measures=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Present factor loadings in table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"dplyr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"tidyr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(tidyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"knitr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(knitr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterEstimates(fit, standardized=TRUE) %>% \n",
    "  filter(op == \"=~\") %>% \n",
    "  select('Latent Factor'=lhs, Indicator=rhs, B=est, SE=se, Z=z, 'p-value'=pvalue, Beta=std.all) %>% \n",
    "  kable(digits = 3, format=\"pandoc\", caption=\"Factor Loadings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEM (not required; not part of measurement model testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_sem = 'Perfectionism =~ PER1 + PER2 + PER3\n",
    " Rumination =~ RUM1 + RUM2 + RUM3\n",
    " Exhaustion =~ EX1 + EX2 + EX3 + EX4\n",
    "#regressions\n",
    " Rumination ~ Perfectionism\n",
    " Exhaustion ~ Rumination'\n",
    "\n",
    "fit_sem = sem(model_sem, data=df1)\n",
    "\n",
    "summary(fit_sem, fit.measures=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(fit_sem, 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write.csv(df1, \"C:\\\\iCloudDrive\\\\Documents\\\\Task3_data_winsorized.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the above CFA & SEM analyses were also carried out in RStudios so that I could use the function lavaanPlot to produce figures. The outputs were exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
